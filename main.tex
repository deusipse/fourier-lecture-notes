\documentclass{amsart}

\usepackage[asy, graphs]{amogus}
\usepackage{bm}
\fancyfoot[R]{}
\pgfplotsset{ytick style={draw=none}, xtick style={draw=none}, xticklabels={,,}, yticklabels={,,}} % haven't bothered to find an efficient way to hide the stupid tick marks by default

\title{Lecture Notes---Fourier series}
\author{Edward Wang}

\begin{document}
  \maketitle
  \begin{center}
    \scshape December 2022 \vspace{1em}
  \end{center}
  \tableofcontents
  
  \section{Introduction}

  Fourier series have countless applications throughout applied mathematics and physics. Fourier series were first formally introduced by Joseph Fourier in his 1822 work \emph{ThÃ©orie analytique de la chaleur (Analytical theory of heat)} in order to solve the Heat Equation. Whilst this is not a history lesson, it is still important to know the origin of the Fourier series, which are rooted in physics and are commonly used to solve differential equations.

  \section{Fourier series}

  But what \emph{are} Fourier series? Despite sounding very fancy, the concept is very simple. The general concept of a Fourier series is to break a function down into a sum of sines and cosines. This is motivated by several reasons---they are easily differentiable, integrable, and manipulable.

  For example, given some $2\pi$ periodic function $f(x)$, we can express it as some sum of sinusoidal waves like so:
  \[
    f(x) \approx \frac{a_0}{2} + \sum_{m=1}^{N} (a_m \cos mx + b_m \sin mx)
  .\] If, as the number of terms $N$ approaches $\infty$, the approximation \emph{converges} to $f$, then the resulting sum is called a \emph{Fourier series}:
  \[
    f(x) = \frac{a_0}{2} + \sum_{m=1}^{\infty} (a_m \cos mx + b_m \sin mx)
  .\] You will have noticed that there are some coefficients: $a_0, a_m, b_m$. These are the \emph{Fourier coefficients}, and determine how much of each sine wave of each frequency is included. Before we determine these coefficients, we first discuss the \emph{orthogonality relations} of the sine and cosine functions.

  \section{Orthogonality of sine and cosine}

  There are three important formulae concerning sines and cosines:
  \begin{theorem}[Orthogonality of sine and cosine]
    For integers $m, n$, the following identities hold:
    \begin{align}
      \int_{-\pi}^{\pi} \sin mx \sin nx\, dx &= \begin{cases} 0, \quad m\neq n \\ \pi, \quad m = n \neq 0 \end{cases} \\
      \int_{-\pi}^{\pi} \cos mx \cos nx\, dx &= \begin{cases} 0, \quad m\neq n \\ \pi, \quad m = n \neq 0 \end{cases} \\
      \int_{-\pi}^{\pi} \sin mx \cos nx\, dx &= 0.
    \end{align}
  \end{theorem}
  These identities may be proved using the product to sum trigonometric identities:
  \begin{align}
    \sin a \sin b &= \frac{1}{2}[\cos(a-b) - \cos(a+b)] \label{trig1}\\
    \cos a \cos b &= \frac{1}{2} [\cos (a-b) + \cos(a+b)] \label {trig2}\\
    \sin a \cos b &= \frac{1}{2}[\sin (a-b) + \sin(a+b)] \label{trig3}
  \end{align}
  \begin{proof}
    We use \ref{trig1} to prove the first formula:
    \begin{align*}
      \int_{-\pi}^{\pi} \sin mx \sin nx\, dx &= \frac{1}{2} \int_{-\pi}^{\pi} \cos(x(m-n)) - \cos(x(m+n))\, dx \\
                                             &= \frac{1}{2} \left[ \frac{\sin(x(m-n))}{m-n} - \frac{\sin(x(m+n))}{m+n} \right]_{-\pi}^{\pi}.
    \end{align*}
    Since $\sin k\pi = 0$ for any integer $k$, we have \[
      \int_{-\pi}^{\pi} \sin mx \sin nx \, dx = 0, \quad m\neq n
    .\] However, notice that the method only makes sense for $m\neq n$. If $m = n$, we may use the identity $\sin^2 a = \frac{1}{2}[1 - \cos(2a)]$ to obtain 
    \begin{align*}
      \int_{-\pi}^{\pi} \sin^2(mx)\, dx &= \frac{1}{2} \int_{-\pi}^{\pi} 1 - \cos(2mx)\, dx \\
                                        &= \frac{1}{2} \left[ x - \frac{\sin (2mx)}{2m} \right]_{-\pi}^{\pi} \\
                                        &= \pi.
    \end{align*}
    The other two identities are left as an exercise to the reader.
  \end{proof}

  \section{Fourier Coefficients}

  Recall the Fourier series of $f(x)$, a $2\pi$ periodic function on $[-\pi, \pi]$:
  \begin{equation}
    f(x) = \frac{a_0}{2} + \sum_{m=1}^{\infty} (a_m \cos mx + b_m \sin mx).
  \end{equation}
  Let us assume that the series converges to $f$. We wish to calculate the coefficients $a_0, a_m, b_m$. 

  First, consider multiplying $f(x)$ by $\cos nx$ and integrating from $-\pi$ to $\pi$:
  \begin{align*}
    \int_{-\pi}^{\pi} f(x) \cos nx \, dx = \frac{a_0}{2} \int_{-\pi}^{\pi} \cos nx \, dx &+ \sum_{m=1}^{\infty} a_m \int_{-\pi}^{\pi}\cos mx \cos nx \, dx \\ &+ \sum_{m=1}^{\infty} b_m \int_{-\pi}^{\pi} \sin mx \cos nx \, dx .
  \end{align*}
  Using the orthogonal relationships from earlier, we may simplify this to 
  \begin{align*}
    \int_{-\pi}^{\pi} f(x) \cos nx \, dx &= 0 + a_n \pi + 0\\
    \bm{a_n} &\bm{= \frac{1}{\pi} \int_{-\pi}^{\pi} f(x) \cos nx \, dx} .
  \end{align*}
  Now we multiply $f(x)$ by $\sin nx$ and integrate from $-\pi$ to $\pi$:
  \begin{align*}
    \int_{-\pi}^{\pi} f(x) \sin nx \, dx = \frac{a_0}{2} \int_{-\pi}^{\pi} \sin nx \, dx &+ \sum_{m=1}^{\infty} a_m \int_{-\pi}^{\pi}\sin nx \cos mx \, dx \\ &+ \sum_{m=1}^{\infty} b_m \int_{-\pi}^{\pi} \sin mx \sin nx \, dx .
  \end{align*}
  Again, we simplify using the orthogonal relations:
  \begin{align*}
    \int_{-\pi}^{\pi} f(x) \sin nx\, dx &= 0 + 0 + b_n \pi \\
    \bm{b_n} &= \bm{\frac{1}{\pi} \int_{-\pi}^{\pi} f(x) \sin nx\, dx}. 
  \end{align*}

  Finally, to determine $a_0$, we simply integrate from $-\pi$ to $\pi$:
  \begin{align*}
    \int_{-\pi}^{\pi} f(x)\, dx = \frac{a_0}{2} \int_{-\pi}^{\pi} \, dx &+ \sum_{m=1}^{\infty} a_m \int_{-\pi}^{\pi} \cos mx\, dx \\
                                &+ \sum_{m=1}^{\infty} b_m \int_{-\pi}^{\pi} \sin mx\, dx.
  \end{align*}
  This time, we simply notice that $\int_{-\pi}^{\pi} \cos kx\, dx $ and $\int_{-\pi}^{\pi} \sin kx\, dx$ both equal zero. Hence, we obtain 
  \begin{align*}
    \int_{-\pi}^{\pi} f(x) \, dx &= a_0 \pi + 0 + 0 \\
    \bm{a_0} &\bm{= \frac{1}{\pi} \int_{-\pi}^{\pi} f(x) \, dx}. 
  \end{align*}
  \begin{definition}[Fourier series]
    The \emph{Fourier series} of a function $f(x)$ that is $2\pi$ periodic on the closed interval  $[-\pi, \pi]$ is given by \[
      f(x) = \frac{a_0}{2} + \sum_{m=1}^{\infty} (a_m \cos mx + b_m \sin mx)
    ,\] where 
    \begin{align*}
      a_0 &= \frac{1}{\pi}\int_{-\pi}^{\pi} f(x)\, dx \\
      a_m &= \frac{1}{\pi}\int_{-\pi}^{\pi} f(x)\cos mx\, dx \\
      b_m &= \frac{1}{\pi}\int_{-\pi}^{\pi} f(x)\sin mx\, dx.
    \end{align*}
  \end{definition}

  \section{Using Fourier series}
  \subsection{An example}

  We now look at some applications of Fourier series. Let's go through an example of computing the Fourier series of a function.

  Consider the function $f(x) = x$, which has been made periodic on the interval $[-\pi, \pi]$ so that it is $2\pi$ periodic. This just means that it repeats after $x = \pi$. We will calculate its Fourier coefficients.

  We know that $a_0 = \frac{1}{\pi} \int_{-\pi}^{\pi} f(x) \, dx$. Since $f(x) = x$, we have 
  \begin{align*}
    a_0 &= \frac{1}{\pi} \int_{-\pi}^{\pi} x\, dx \\
        &= \frac{1}{\pi} \left[ \frac{x^2}{2} \right]_{-\pi}^{\pi} \\
        &= 0.
  \end{align*}
  Next, we calculate $a_m$:
  \begin{equation*}
    a_m = \frac{1}{\pi} \int_{-\pi}^{\pi} x\cos mx \, dx.
  \end{equation*}
  Notice $f(x) = x$ is an odd function, and $\cos mx$ is an even function. Therefore $x\cos mx$ is an odd function. When integrating an odd function with symmetric bounds, the result is always 0. Hence, $a_m = 0$.

  Finally, we calculate $b_m$.
  \begin{equation*}
    b_m = \frac{1}{\pi}\int_{-\pi}^{\pi} x \sin mx \, dx .
  \end{equation*}
  This is a simple integration by parts exercise:
  \begin{align*}
    b_m &= \frac{1}{\pi} \left[ -\frac{x\cos mx}{m} + \frac{1}{m}\int \cos mx\, dx \right]_{-\pi}^{\pi} \\
        &= \frac{1}{\pi} \left[ \frac{\sin mx - mx\cos mx}{m^2} \right]_{-\pi}^{\pi}.
  \end{align*}
  Notice that $\sin m\pi = 0$ for any integer $m$, and $\cos m\pi = (-1)^{m}$. Hence we have 
  \begin{align*}
    b_m &= \frac{1}{\pi} \left[ \frac{-2\pi m(-1)^{m}}{m^2} \right] \\
        &= -\frac{2(-1)^{m}}{m}.
  \end{align*}
  This gives us the Fourier series \[
    f(x) = - \sum_{m=1}^{\infty} \frac{2(-1)^m}{m} \sin mx
  .\] The graphs of some partial sums are shown in Figures \ref{fig:2} and \ref{fig:3}.
  \begin{figure}
    \begin{tikzpicture}
      \begin{axis}[axis lines = middle, domain = -3*pi : 3*pi, axis equal, ymax=pi, ymin = -pi, clip=false, xticklabels={$-2\pi$, $2\pi$}, xtick={-6.28318530718, 6.28318530718}, xtick style={draw}, width = \textwidth, height = 6cm]
        \addplot[domain = -pi : pi] {x};
        \addplot[domain = -3*pi : -pi] {x+2*pi};
        \addplot[domain = pi: 3*pi] {x-2*pi};
        \draw (0, pi) node[right] {$f(x)$};
      \end{axis}
    \end{tikzpicture}
    \caption{Graph of $f(x)$}
  \end{figure}
  \begin{figure}
    \begin{tikzpicture}
      \begin{axis}[axis lines = middle, domain = -3*pi : 3*pi, axis equal, ymax=pi, ymin = -pi, clip=false, xticklabels={$-2\pi$, $2\pi$}, xtick={-6.28318530718, 6.28318530718}, xtick style={draw}, width = \textwidth, height = 6cm]
    \addplot gnuplot[raw gnuplot, mark = none, black] {
      set samples 1000;      % final copy can have 1000 samples
      set xrange[-3*pi:3*pi];
      set yrange[-pi:pi];
      fourier(x, k) = sin(k*x)*(-2*(-1)**k)/k;
      series(x,n) = (n>0 ? fourier(x,n) + series(x,n-1) : 0);
      plot[-3*pi:3*pi] series(x, 1);
      plot[-3*pi:3*pi] series(x, 2);
      plot[-3*pi:3*pi] series(x, 3);
      plot[-3*pi:3*pi] series(x, 4);
    };
      \end{axis}
    \end{tikzpicture}
    \caption{Graphs of the first 4 partial sums}
    \label{fig:2}
  \end{figure}
  \begin{figure}
    \begin{tikzpicture}
      \begin{axis}[axis lines = middle, domain = -3*pi : 3*pi, axis equal, ymax=pi, ymin = -pi, clip=false, xticklabels={$-2\pi$, $2\pi$}, xtick={-6.28318530718, 6.28318530718}, xtick style={draw}, width = \textwidth, height = 6cm]
    \addplot gnuplot[raw gnuplot, mark = none, black] {
      set samples 10000;             % final copy can have 10000 samples because it looks better :)
      set xrange[-3*pi:3*pi];
      set yrange[-pi:pi];
      fourier(x, k) = sin(k*x)*(-2*(-1)**k)/k;
      series(x,n) = (n>0 ? fourier(x,n) + series(x,n-1) : 0);
      plot[-3*pi:3*pi] series(x, 100);
    };
      \end{axis}
    \end{tikzpicture}
    \caption{Graph of the 100th partial sum}
    \label{fig:3}
  \end{figure}

  \subsection{The Basel Problem}

  You may have heard of the Basel problem, an astonishing identity where $\pi$ seemingly randomly pops up. I will present a method of solving the problem using Fourier series.
  \begin{theorem}[Basel problem]
    \[
      \sum_{n = 1}^{\infty} \frac{1}{n^2} = \frac{\pi^2}{6}
    .\] 
  \end{theorem}
  \begin{proof}
    Consider the function $f(x) = x^2$ which has been made periodic on the interval $[-\pi, \pi]$. We now find its Fourier series.

    First, we calculate $a_0$:
    \begin{align*}
      a_0 &= \frac{1}{\pi} \int_{-\pi}^{\pi} x^2 \, dx \\
          &= \frac{2}{\pi}\left[ \frac{x^3}{3} \right]_{0}^{\pi} \\
          &= \frac{2\pi^2}{3}.
    \end{align*}
    Next, we calculate $a_m$, using integration by parts:
    \begin{align*}
      a_m &= \frac{1}{\pi} \int_{-\pi}^{\pi} x^2 \cos mx \, dx \\
          &= \frac{1}{\pi} \left[ \frac{x^2 \sin mx}{m} - \frac{2}{m} \int x \sin mx \, dx \right]_{-\pi}^{\pi} .
    \end{align*}
    We can use our previous result that $\int_{-\pi}^{\pi} x \sin mx \, dx = -\frac{2\pi(-1)^{m}}{m}$ to get
    \begin{align*}
      a_m &= \frac{1}{\pi} \left[ \frac{x^2 \sin mx}{m} \right]_{-\pi}^{\pi} + \frac{2}{\pi m}\left[ \frac{2\pi(-1)^{m}}{m} \right] \\
          &= \frac{4(-1)^{m}}{m^{2}}.
    \end{align*}
    To calculate $b_m$ we may notice that $x^2 \sin mx$ is odd, meaning that the symmetric integral will be 0. Hence, $b_m = 0$.

    This means that our Fourier series for $f(x) = x^2$ on $[-\pi, \pi]$ is \[
      f(x) = x^2 = \frac{\pi^2}{3} + \sum_{m=1}^{\infty} \frac{4(-1)^{m}}{m^2} \cos mx
    .\] 
  Let's now observe what happens when we plug in $x = \pi$. We get 
  \begin{align*}
    f(\pi) = \pi^2 &= \frac{\pi^2}{3} + \sum_{m=1}^{\infty} \frac{4(-1)^{m}}{m^2}\cos(m \pi) \\
    \frac{2\pi^2}{3} &= \sum_{m=1}^{\infty} \frac{4}{m^2} .
  \end{align*}
  Dividing both sides by 4 yields the result that \[
    \frac{\pi^2}{6} = \sum_{n=1}^{\infty} \frac{1}{n^2}. \qedhere
  \] 
\end{proof}

  \section{Wave Equation in One Dimension}
  
  We now investigate the problem of a vibrating string.

  Consider a string of length $L$ lying on the $x$-axis, fixed at 2 ends: the origin $(0, 0)$ and $(L, 0)$. We will make some reasonable assumptions:
  \begin{itemize}
    \item The particles in the string move only up and down (there is no horizontal movement)
    \item The string is perfectly elastic
  \end{itemize}Let the function $u(x, t)$ describe the displacement of the string at time $t$.
  \begin{figure}[H]
    \centering
    \begin{tikzpicture}
      \begin{axis}[axis lines = left, width = \columnwidth, height = 5cm, ymax = 1, xmax = pi+0.3, clip = false, smooth]
        \addplot[domain = 0:pi] {0.5*sin(deg(x))};
        \draw (0, 0.9) node[right] {$u(x, t)$};
        \draw (pi+0.25, 0) node[above] {$x$};
        \draw[fill=black] (pi, 0) circle (2pt) node[below] {$(L, 0)$};
        \draw[fill=black] (0, 0) circle (2pt) node[below] {$(0, 0)$};
      \end{axis}
    \end{tikzpicture}
    \caption{A possible shape of the string at some point in time}
  \end{figure}
  First, we find the mass of the string in some interval $[a, b]$. Let  $\rho(x, t)$ describe the density of the string at  $x$ at time $t$. Focus on a tiny segment of the string at $x$.
  \begin{figure}[H]
    \begin{tikzpicture}
      \draw[very thick] (2, 1) -- (8, 3);
      \draw[dashed] (2, 1) -- (2, 0) node[below] {$x$} (8, 3) -- (8, 0) node[below] {$x + \Delta x$};
      \draw[dashed] (2, 1) -- (8, 1) node[midway, below] {$\Delta x$}; 
      \path(8, 3) -- (8, 1) node[midway, right] {$\Delta y$};
      \draw[->] (0, 0) -- (10, 0);
    \end{tikzpicture}
  \end{figure}
  Since this piece of string is so small, it approximates a straight line. Hence its length is clearly $\sqrt{\Delta x^2 + \Delta y^2} = \sqrt{1 + \big(\frac{\Delta y}{\Delta x}\big)^2}\Delta x$. Now the mass of this piece of string is simply $\rho(x, t)\sqrt{1 + \big(\frac{\Delta y}{\Delta x}\big)^2}\Delta x$. Imagine summing this $N$ times for all the tiny segments in the interval $[a, b]$. Thus an approximation of the mass of the string  in the interval $[a, b]$ is \[
    \sum_{i=1}^{N} \rho(x, t)\sqrt{1 + \Big(\frac{\Delta y_i}{\Delta x_i}\Big)^2}\Delta x_i
  .\] If these segments are equally spaced, then $\Delta x_i = \Delta x$. Our approximation becomes the true mass of the string when  $\Delta x$ approaches 0 and $N$ approaches $\infty$. Thus the mass of the string is \[
  \lim_{\substack{N \to \infty \\ \Delta x \to 0}} \sum_{i=1}^{N} \rho(x, t)\sqrt{1 + \Big(\frac{\Delta y_i}{\Delta x}\Big)^2}\Delta x = \int_{a}^{b} \rho(x, t)\sqrt{1 + \Big(\frac{\partial u}{\partial x}\Big)^2}\, dx
.\] For sake of brevity, we abbreviate $\frac{\partial u}{\partial x}$ to  $u_x$, and similarly, $\frac{\partial u}{\partial t}$ to $u_t$.

Let us now concentrate on another small segment of the string in the interval $[x, x + \Delta x]$. This piece of string has mass \[
  \int_{x}^{x+\Delta x} \rho(x, t)\sqrt{1 + u_x^2}\, dx.
\] Let $m = \rho(x, t) \sqrt{1 + u_x^2} $ such that the mass is $\int_{x}^{x+\Delta x} m\, dx $.
  \begin{figure}[H]
    \centering
    \begin{tikzpicture}
      \begin{axis}[clip = false, ymin = 0, ymax = 1, height = 5cm, width = \columnwidth, axis lines = left, xmin = 0, xmax = pi/2 + 0.4]
        \addplot[domain = 0.5 : pi/2-0.2, very thick] {sin(deg(x))};
        \addplot[domain = 0.3 : 0.8, <-] {cos(deg(0.5)) * (x-0.5) + sin(deg(0.5))};
        \addplot[domain = pi/2 - 0.5 : pi/2+0.1, ->] {cos(deg(pi/2 - 0.2)) * (x-pi/2 + 0.2) + sin(deg(pi/2 - 0.2))};
        \addplot[domain = 0.3:pi/2] {0};
        \filldraw (0.5, 0.479426) circle (1.5pt);
        \filldraw (0.5, 0.479426) circle (1.5pt);
        \filldraw (pi/2 - 0.2, 0.9800665) circle (1.5pt);
        \draw[dashed] (0.5, 0.479426) -- (0.5, 0) node[below] {$x$} (0.5, 0.479426) -- (0.5+0.25, 0.479426);
        \draw[dashed] (pi/2 - 0.2, 0.9800665) -- (pi/2 - 0.2, 0) node[below] {$x + \Delta x$} (pi/2 - 0.2, 0.9800665) -- (pi/2 - 0.2 + 0.25, 0.9800665);
        \draw (0.5+0.1, 0.479426) arc(0:41.27:0.1) node[midway, right, xshift = 3pt, yshift = 3pt] {$\theta_x$};
        \draw (pi/2 - 0.2 + 0.1, 0.9800665) arc(0:11.24:0.1) node[below right] {$\theta_{x + \Delta x}$};
      \end{axis}
    \end{tikzpicture}
    \caption{}
  \end{figure}
  Consider the tension forces $T_x$ and $T_{x+\Delta x}$ at $x$ and $x+\Delta x$ respectively. Since the net horizontal movement is 0, the sum of the horizontal components of the tension must be 0. This means that 
  \begin{align*}
    T_{x}\cos \theta_x &= T_{x+\Delta x}\cos \theta_{x+\Delta x} \\
    T_{x+\Delta x} \cos \theta_{x + \Delta } - T_{x} \cos \theta_x &= 0.
  \end{align*}
  If we divide by $\Delta x$ and let $\Delta x \to 0$, by the definition of the derivative, we get
  \begin{align*}
    \lim_{\Delta x\to 0} \frac{T_{x+\Delta x} \cos \theta_{x + \Delta } - T_{x} \cos \theta_x}{\Delta x} &= 0 \\
    \frac{\partial}{\partial x} T_x \cos \theta_x &= 0.
  \end{align*}
  Hence $T_x \cos \theta_x$ must be a constant, which we will call $\tau$.

  Next, we consider the vertical tensional forces. We have 
  \begin{align*}
    \sum T = T_{x+\Delta x} \sin \theta_{x+\Delta x} - T_{x} \sin \theta_{x} &= \tau \Big(\frac{\sin \theta_{x+\Delta x}}{\cos \theta_{x+\Delta x}} - \frac{\sin \theta_x}{\cos \theta_x} \Big) \\
                                                                             &= \tau (\tan \theta_{x + \Delta x} - \tan \theta_{x}).
  \end{align*}
  Since $\tan \theta$ is simply the slope, we may replace it with $u_x$, giving us the net force \[
    F = \tau (u_{x}(x+\Delta x, t) - u_{x}(x))
  .\] 
  We now have the force and the mass. We simply need the acceleration to apply Newton's second law. Thankfully, the acceleration is simply the second time derivative, $u_{tt}$. Applying Newton's second law, which states that $\sum F = ma$, we get:
  \begin{equation}\label{eq1}
    \tau (u_{x}(x+\Delta x, t) - u_{x}(x)) = \int_{x}^{x+\Delta x} mu_{tt}\, dx . 
  \end{equation}
  The Intermediate Value Theorem for integrals states that \[
    \int_{a}^{b} f(x)\, dx = f(c)(b-a)
  \] for some $c \in [a, b]$. We use this to simplify \ref{eq1}: 
  \[
    \tau (u_{x}(x+\Delta x, t) - u_{x}(x)) = mu_{tt}\Delta x
  .\] We then divide by $\Delta x$ and let $\Delta \to 0$:
  \begin{align*}
    \tau \frac{u_x(x+\Delta x, t) - u_{x}(x, t)}{\Delta x} &= mu_{tt} \\
    \tau u_{xx} &= mu_{tt}.
  \end{align*}
  If we define a constant $c = \sqrt{\frac{\tau}{m}} $, then we may rewrite the equation as \[
    u_{tt} = c^2 u_{xx}
  .\] This is the wave equation, in one spatial dimension.
  \begin{definition}
    The one-dimensional \emph{wave equation} is \[
      u_{tt} = c^2u_{xx}
    ,\] such that $u(x, t)$ describes the motion of a plucked string over time.
  \end{definition}

  \section{Solving the wave equation}

  Some bollocks
\end{document}
